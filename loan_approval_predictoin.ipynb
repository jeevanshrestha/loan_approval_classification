{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84894,"databundleVersionId":9709193,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shresthajeevan/loan-approval-prediction-classification?scriptVersionId=211279989\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:30.609661Z","iopub.execute_input":"2024-12-05T00:04:30.610124Z","iopub.status.idle":"2024-12-05T00:04:30.620662Z","shell.execute_reply.started":"2024-12-05T00:04:30.610089Z","shell.execute_reply":"2024-12-05T00:04:30.61956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nimport pylab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:33.043749Z","iopub.execute_input":"2024-12-05T00:04:33.044157Z","iopub.status.idle":"2024-12-05T00:04:33.051316Z","shell.execute_reply.started":"2024-12-05T00:04:33.044122Z","shell.execute_reply":"2024-12-05T00:04:33.0504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.exceptions import ConvergenceWarning\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_curve\n\nimport lightgbm as lgb \nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:36.172103Z","iopub.execute_input":"2024-12-05T00:04:36.172499Z","iopub.status.idle":"2024-12-05T00:04:36.179542Z","shell.execute_reply.started":"2024-12-05T00:04:36.172464Z","shell.execute_reply":"2024-12-05T00:04:36.178238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:37.154309Z","iopub.execute_input":"2024-12-05T00:04:37.154742Z","iopub.status.idle":"2024-12-05T00:04:37.160396Z","shell.execute_reply.started":"2024-12-05T00:04:37.154706Z","shell.execute_reply":"2024-12-05T00:04:37.159115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s4e10/train.csv',index_col='id' )\ndf_test = pd.read_csv('/kaggle/input/playground-series-s4e10/test.csv',index_col='id' )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:37.714021Z","iopub.execute_input":"2024-12-05T00:04:37.714404Z","iopub.status.idle":"2024-12-05T00:04:37.951497Z","shell.execute_reply.started":"2024-12-05T00:04:37.714371Z","shell.execute_reply":"2024-12-05T00:04:37.950636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = df_train['loan_status']\nX = df_train.drop(columns='loan_status') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:38.13799Z","iopub.execute_input":"2024-12-05T00:04:38.138936Z","iopub.status.idle":"2024-12-05T00:04:38.148415Z","shell.execute_reply.started":"2024-12-05T00:04:38.138887Z","shell.execute_reply":"2024-12-05T00:04:38.147244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:38.577462Z","iopub.execute_input":"2024-12-05T00:04:38.578256Z","iopub.status.idle":"2024-12-05T00:04:38.605064Z","shell.execute_reply.started":"2024-12-05T00:04:38.578216Z","shell.execute_reply":"2024-12-05T00:04:38.603829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:38.865796Z","iopub.execute_input":"2024-12-05T00:04:38.866766Z","iopub.status.idle":"2024-12-05T00:04:38.899186Z","shell.execute_reply.started":"2024-12-05T00:04:38.866725Z","shell.execute_reply":"2024-12-05T00:04:38.898101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:39.080378Z","iopub.execute_input":"2024-12-05T00:04:39.080755Z","iopub.status.idle":"2024-12-05T00:04:39.087288Z","shell.execute_reply.started":"2024-12-05T00:04:39.080725Z","shell.execute_reply":"2024-12-05T00:04:39.086214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:39.276659Z","iopub.execute_input":"2024-12-05T00:04:39.277377Z","iopub.status.idle":"2024-12-05T00:04:39.285839Z","shell.execute_reply.started":"2024-12-05T00:04:39.277311Z","shell.execute_reply":"2024-12-05T00:04:39.284915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:39.515168Z","iopub.execute_input":"2024-12-05T00:04:39.515887Z","iopub.status.idle":"2024-12-05T00:04:39.562221Z","shell.execute_reply.started":"2024-12-05T00:04:39.515843Z","shell.execute_reply":"2024-12-05T00:04:39.561252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:39.747059Z","iopub.execute_input":"2024-12-05T00:04:39.747565Z","iopub.status.idle":"2024-12-05T00:04:39.765073Z","shell.execute_reply.started":"2024-12-05T00:04:39.747529Z","shell.execute_reply":"2024-12-05T00:04:39.763868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_columns = df_train.select_dtypes(include=['number']).columns.drop(y.name).tolist()\ncategorical_columns = df_train.select_dtypes(include=['object']).columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:39.957273Z","iopub.execute_input":"2024-12-05T00:04:39.957674Z","iopub.status.idle":"2024-12-05T00:04:39.965714Z","shell.execute_reply.started":"2024-12-05T00:04:39.957641Z","shell.execute_reply":"2024-12-05T00:04:39.964825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:40.705797Z","iopub.execute_input":"2024-12-05T00:04:40.706171Z","iopub.status.idle":"2024-12-05T00:04:40.730223Z","shell.execute_reply.started":"2024-12-05T00:04:40.70614Z","shell.execute_reply":"2024-12-05T00:04:40.72935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Exploratory Data Analysis\n","metadata":{}},{"cell_type":"code","source":" \n# Box plot on the left\nsns.countplot(x=y ,palette='Set2' , color=y  )\n \nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:41.970964Z","iopub.execute_input":"2024-12-05T00:04:41.971354Z","iopub.status.idle":"2024-12-05T00:04:42.302043Z","shell.execute_reply.started":"2024-12-05T00:04:41.971305Z","shell.execute_reply":"2024-12-05T00:04:42.301055Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Numerical Variables Distributions and Correlations Pairplots","metadata":{}},{"cell_type":"code","source":"# Compute the correlation matrix\ncorrelation_matrix = df_train[numerical_columns].corr()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T08:44:00.912095Z","iopub.execute_input":"2024-12-04T08:44:00.912468Z","iopub.status.idle":"2024-12-04T08:44:00.934319Z","shell.execute_reply.started":"2024-12-04T08:44:00.912431Z","shell.execute_reply":"2024-12-04T08:44:00.932977Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the correlation matrix\nplt.figure(figsize=(16, 12))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)\n\n# Set plot labels\nplt.title('Correlation Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T08:44:00.936255Z","iopub.execute_input":"2024-12-04T08:44:00.936787Z","iopub.status.idle":"2024-12-04T08:44:01.520548Z","shell.execute_reply.started":"2024-12-04T08:44:00.936735Z","shell.execute_reply":"2024-12-04T08:44:01.519221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create pairplot with KDE only on the diagonal\nsns.pairplot(df_train[numerical_columns], diag_kind='kde')\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T08:44:01.522175Z","iopub.execute_input":"2024-12-04T08:44:01.522666Z","iopub.status.idle":"2024-12-04T08:44:21.892432Z","shell.execute_reply.started":"2024-12-04T08:44:01.522591Z","shell.execute_reply":"2024-12-04T08:44:21.890994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Set up the matplotlib figure with subplots\nplt.figure(figsize=(20, 30))\n\n# Loop through each numerical column and create a histogram\nfor i, col in enumerate(numerical_columns):\n    plt.subplot(10, 4, i + 1)  # Adjust the number of rows and columns as needed\n    sns.histplot(df_train[col], kde=True, bins=15 )  # 'kde=True' adds a kernel density estimate\n    plt.title(f'Histogram of {col}')\n    plt.xlabel(col)\n    plt.ylabel('Frequency')\n\n# Adjust layout to prevent overlapping\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T08:44:21.89403Z","iopub.execute_input":"2024-12-04T08:44:21.894449Z","iopub.status.idle":"2024-12-04T08:44:26.16817Z","shell.execute_reply.started":"2024-12-04T08:44:21.894407Z","shell.execute_reply":"2024-12-04T08:44:26.166488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train[numerical_columns].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T08:44:26.169701Z","iopub.execute_input":"2024-12-04T08:44:26.170174Z","iopub.status.idle":"2024-12-04T08:44:26.219931Z","shell.execute_reply.started":"2024-12-04T08:44:26.170123Z","shell.execute_reply":"2024-12-04T08:44:26.218684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up the matplotlib figure with subplots\nplt.figure(figsize=(20, 30))\n\n# Loop through each numerical column and create a box plot\nfor i, col in enumerate(numerical_columns):\n    plt.subplot(10, 4, i + 1)  # Adjust the number of rows and columns as needed\n    sns.boxplot(data=df_train, x=col)  # Box plot for each numerical column\n    plt.title(f'Box Plot of {col}')\n    plt.xlabel(col)\n\n# Adjust layout to prevent overlapping\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T08:44:26.22168Z","iopub.execute_input":"2024-12-04T08:44:26.222161Z","iopub.status.idle":"2024-12-04T08:44:27.567108Z","shell.execute_reply.started":"2024-12-04T08:44:26.222114Z","shell.execute_reply":"2024-12-04T08:44:27.565772Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Categorical Variables Distribution","metadata":{}},{"cell_type":"code","source":"# Plot distribution of SalesPrice vs each categorical column\nplt.figure(figsize=(16, 12))\n\nfor i, col in enumerate(categorical_columns):\n    plt.subplot(2,2, i + 1)  # Adjust the grid size based on the number of categorical columns\n    sns.countplot(x=df_train[col], palette=\"Set2\", hue=y)\n    plt.xticks(rotation=45)  # Rotate x-axis labels if needed\n    plt.title(f'Distribution   {col}')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T08:44:27.568834Z","iopub.execute_input":"2024-12-04T08:44:27.56932Z","iopub.status.idle":"2024-12-04T08:44:28.811223Z","shell.execute_reply.started":"2024-12-04T08:44:27.569272Z","shell.execute_reply":"2024-12-04T08:44:28.809934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HandleOutliers(BaseEstimator, TransformerMixin):\n    def __init__(self, p_min=0.01, p_max=0.99):\n        self.p_min = p_min\n        self.p_max = p_max\n\n    def fit(self, X, y=None):\n        # Fit method is required by the estimator interface but we don't need to do anything here\n        return self\n\n    def transform(self, X):\n        X = pd.DataFrame(X)  # Ensure it's a DataFrame for easy processing\n        for column in X.columns:\n            # Calculate the min and max percentiles\n            p_min_value = X[column].quantile(self.p_min)\n            p_max_value = X[column].quantile(self.p_max)\n\n            # Replace values below min percentile and above max percentile\n            X[column] = X[column].clip(lower=p_min_value, upper=p_max_value)\n\n            # Replace missing values with the median\n            median = X[column].median()\n            X[column] = X[column].fillna(median)\n\n        return X.values  # Return as numpy array for compatibility with sklearn\n\n    def get_feature_names_out(self, input_features=None):\n        # Return the same feature names as input\n        return input_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:46.98667Z","iopub.execute_input":"2024-12-05T00:04:46.987633Z","iopub.status.idle":"2024-12-05T00:04:46.996002Z","shell.execute_reply.started":"2024-12-05T00:04:46.987539Z","shell.execute_reply":"2024-12-05T00:04:46.994676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AgeToRangeTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, age_column):\n        self.age_column = age_column  # Allow passing the column name dynamically\n\n    def fit(self, X, y=None):\n        return self  # No fitting needed\n\n    def transform(self, X):\n        # Ensure the provided column exists in the data\n        if self.age_column not in X.columns:\n            raise ValueError(f\"Column '{self.age_column}' not found in the input data.\")\n        \n        # Create the 'age_range' column based on the age column\n        age_range = pd.cut(X[self.age_column], bins=[0, 20, 25, 30, 35, 40, 50, float('inf')],\n                           labels=['Below 20', '20-25', '25-30', '30-35', '35-40', '40-50', '50+'])\n        \n        X['age_range'] = age_range  # Add the new 'age_range' column\n        X = X.drop(columns=[self.age_column])  # Drop the original age column\n        \n        return X\n\n    def get_feature_names_out(self, input_features=None):\n        # Return the feature names after the transformation, which will be 'age_range'\n        return ['age_range']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:47.513719Z","iopub.execute_input":"2024-12-05T00:04:47.514094Z","iopub.status.idle":"2024-12-05T00:04:47.524419Z","shell.execute_reply.started":"2024-12-05T00:04:47.51406Z","shell.execute_reply":"2024-12-05T00:04:47.523459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Create a pipeline for age transformation followed by one-hot encoding\nage_pipeline = Pipeline(steps=[\n    ('age_transformation',  AgeToRangeTransformer(age_column='person_age')),  # Apply age transformation\n    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))  # OneHotEncode the age_range column\n])\n\n# Define the numerical pipeline: Handle outliers followed by standard scaling\nnumerical_pipeline = Pipeline(steps=[\n    ('outlier_handling', HandleOutliers(p_min=0.0025, p_max=0.9975)),  # Apply outlier handling\n    ('scaling', StandardScaler())  # Apply standard scaling\n])\n\n# ColumnTransformer with age_pipeline to handle age range + other transformations\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"age_transformation\", age_pipeline, ['person_age']),  # Apply to 'person_age'\n        (\"num_transformation\", numerical_pipeline, [col for col in numerical_columns if col != 'person_age']),  # Exclude 'person_age'\n        (\"cat_transformation\", OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_columns)  # OneHotEncode other categorical columns\n    ],\n    remainder='passthrough'  # Pass through any columns not explicitly transformed\n)\n\n \n# Create a pipeline with PCA or any other estimator after preprocessing\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor)  # Apply preprocessing for both categorical and numerical columns\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:04:47.970006Z","iopub.execute_input":"2024-12-05T00:04:47.970404Z","iopub.status.idle":"2024-12-05T00:04:47.977837Z","shell.execute_reply.started":"2024-12-05T00:04:47.970363Z","shell.execute_reply":"2024-12-05T00:04:47.976693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipeline.fit(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:05:12.893984Z","iopub.execute_input":"2024-12-05T00:05:12.894382Z","iopub.status.idle":"2024-12-05T00:05:13.103737Z","shell.execute_reply.started":"2024-12-05T00:05:12.894319Z","shell.execute_reply":"2024-12-05T00:05:13.102659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformed_X = pipeline.transform(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:05:14.018285Z","iopub.execute_input":"2024-12-05T00:05:14.018701Z","iopub.status.idle":"2024-12-05T00:05:14.153152Z","shell.execute_reply.started":"2024-12-05T00:05:14.018668Z","shell.execute_reply":"2024-12-05T00:05:14.152059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # Get the feature names after transformation\ntransformed_feature_names = preprocessor.get_feature_names_out()\ntransformed_feature_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:05:14.681832Z","iopub.execute_input":"2024-12-05T00:05:14.682223Z","iopub.status.idle":"2024-12-05T00:05:14.689582Z","shell.execute_reply.started":"2024-12-05T00:05:14.682186Z","shell.execute_reply":"2024-12-05T00:05:14.688561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_transformed_X =  pd.DataFrame(transformed_X, columns=transformed_feature_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:05:15.322157Z","iopub.execute_input":"2024-12-05T00:05:15.323205Z","iopub.status.idle":"2024-12-05T00:05:15.327902Z","shell.execute_reply.started":"2024-12-05T00:05:15.323165Z","shell.execute_reply":"2024-12-05T00:05:15.326755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_transformed_X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:05:15.809577Z","iopub.execute_input":"2024-12-05T00:05:15.809973Z","iopub.status.idle":"2024-12-05T00:05:15.854517Z","shell.execute_reply.started":"2024-12-05T00:05:15.809937Z","shell.execute_reply":"2024-12-05T00:05:15.853508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" \n# Perform the split\nX_train, X_test, y_train, y_test = train_test_split(df_transformed_X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:05:16.049267Z","iopub.execute_input":"2024-12-05T00:05:16.049699Z","iopub.status.idle":"2024-12-05T00:05:16.066008Z","shell.execute_reply.started":"2024-12-05T00:05:16.049662Z","shell.execute_reply":"2024-12-05T00:05:16.065097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def print_correlation_heatmap(confusion_matrix):\n    plt.figure(figsize=(8,6))\n    sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:05:16.252992Z","iopub.execute_input":"2024-12-05T00:05:16.253406Z","iopub.status.idle":"2024-12-05T00:05:16.26211Z","shell.execute_reply.started":"2024-12-05T00:05:16.253368Z","shell.execute_reply":"2024-12-05T00:05:16.261042Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Apply Machine Learing Algorithms","metadata":{}},{"cell_type":"markdown","source":"#### XGBoost","metadata":{}},{"cell_type":"code","source":"# Define the XGBoost model\nxgb_model = XGBClassifier()\n\n# Define hyperparameters for tuning\nparam_grid = {\n    'n_estimators': [ 100, 150],\n    'learning_rate': [0.01, 0.1],\n    'max_depth': [3, 5, 7],\n    'subsample': [0.8, 1.0],\n    'colsample_bytree': [0.8, 1.0]\n}\n\n# Perform hyperparameter tuning using GridSearchCV\ngrid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\ngrid_search_xgb.fit(X_train, y_train)\n\n# Print best parameters and best score\nprint(\"Best Parameters:\", grid_search_xgb.best_params_)\nprint(\"Training Accuracy:\", grid_search_xgb.best_score_) \n\n\n# Get the best model from grid search\nbest_xg_model = grid_search_xgb.best_estimator_\n\n# Make predictions on the test set\ny_pred_xgb = best_xg_model.predict(X_test)\n\n# Calculate error and accuracy of the model \ntest_accuracy_xgb= accuracy_score(y_test, y_pred_xgb)\n \nprint(f\"Test Accuracy XG : {test_accuracy_xgb}\")\n\nprint(classification_report(y_test, y_pred_xgb))\n\nxgboost_confusion_matrix = confusion_matrix(y_test, y_pred_xgb)\nprint_correlation_heatmap(xgboost_confusion_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:05:18.274041Z","iopub.execute_input":"2024-12-05T00:05:18.27446Z","iopub.status.idle":"2024-12-05T00:07:49.682685Z","shell.execute_reply.started":"2024-12-05T00:05:18.274422Z","shell.execute_reply":"2024-12-05T00:07:49.681687Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Ligth GBM Model","metadata":{}},{"cell_type":"code","source":"# Suppress LightGBM warnings \nwarnings.filterwarnings('ignore', category=UserWarning, module='lightgbm')\n\n\n# Define the LGBM model\nlgbm_model = LGBMClassifier(verbose = -1)\n\n# Define hyperparameters for tuning\nparam_grid = {\n    'n_estimators': [100, 150],\n    'learning_rate': [0.01, 0.1],\n    'max_depth': [3, 5, 7],\n    'subsample': [0.8, 1.0],\n    'colsample_bytree': [0.8, 1.0],\n    'num_leaves': [31, 50],   # Specific to LightGBM \n}\n\n# Perform hyperparameter tuning using GridSearchCV\ngrid_search_lgbm = GridSearchCV(estimator=lgbm_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1)\ngrid_search_lgbm.fit(X_train, y_train)\n\n# Print best parameters and best score\nprint(\"Best Parameters:\", grid_search_lgbm.best_params_)\nprint(\"Training Accuracy:\", grid_search_lgbm.best_score_)\n\n# Get the best model from grid search\nbest_lgbm_model = grid_search_lgbm.best_estimator_\n\n# Make predictions on the test set\ny_pred_lgbm = best_lgbm_model.predict(X_test)\n\n# Calculate error and accuracy of the model \ntest_accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\nprint(f\"Test Accuracy LightGBM: {test_accuracy_lgbm}\")\n\n# Print classification report\nprint(classification_report(y_test, y_pred_lgbm))\n\n# Confusion Matrix and Correlation Heatmap\nlgbm_confusion_matrix = confusion_matrix(y_test, y_pred_lgbm)\n\n# Print confusion matrix heatmap\nprint_correlation_heatmap(lgbm_confusion_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:07:49.68466Z","iopub.execute_input":"2024-12-05T00:07:49.685Z","iopub.status.idle":"2024-12-05T00:11:55.522836Z","shell.execute_reply.started":"2024-12-05T00:07:49.684969Z","shell.execute_reply":"2024-12-05T00:11:55.521729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformed_test = pipeline.transform(df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:11:55.524313Z","iopub.execute_input":"2024-12-05T00:11:55.524794Z","iopub.status.idle":"2024-12-05T00:11:55.629351Z","shell.execute_reply.started":"2024-12-05T00:11:55.52474Z","shell.execute_reply":"2024-12-05T00:11:55.628284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_transformed_test  =  pd.DataFrame(transformed_test, columns=transformed_feature_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:11:55.631978Z","iopub.execute_input":"2024-12-05T00:11:55.63244Z","iopub.status.idle":"2024-12-05T00:11:55.637573Z","shell.execute_reply.started":"2024-12-05T00:11:55.632388Z","shell.execute_reply":"2024-12-05T00:11:55.63666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred_xgb = best_xg_model.predict(df_transformed_test)\nY_pred_lgbm = best_lgbm_model.predict(df_transformed_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:11:55.638777Z","iopub.execute_input":"2024-12-05T00:11:55.639052Z","iopub.status.idle":"2024-12-05T00:11:56.144907Z","shell.execute_reply.started":"2024-12-05T00:11:55.639025Z","shell.execute_reply":"2024-12-05T00:11:56.143844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_xgb = pd.DataFrame(Y_pred_xgb, index=df_test.index, columns=['loan_status']).reset_index()\noutput_lgbm = pd.DataFrame(Y_pred_lgbm, index=df_test.index, columns=['loan_status']).reset_index()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:11:56.146193Z","iopub.execute_input":"2024-12-05T00:11:56.146651Z","iopub.status.idle":"2024-12-05T00:11:56.154829Z","shell.execute_reply.started":"2024-12-05T00:11:56.146609Z","shell.execute_reply":"2024-12-05T00:11:56.153716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_xgb.to_csv('/kaggle/working/submission_xgb.csv', index=False)\noutput_lgbm.to_csv('/kaggle/working/submission_lgbm.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:11:56.155976Z","iopub.execute_input":"2024-12-05T00:11:56.156252Z","iopub.status.idle":"2024-12-05T00:11:56.225006Z","shell.execute_reply.started":"2024-12-05T00:11:56.156225Z","shell.execute_reply":"2024-12-05T00:11:56.22402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_lgbm.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:12:41.055352Z","iopub.execute_input":"2024-12-05T00:12:41.056107Z","iopub.status.idle":"2024-12-05T00:12:41.09214Z","shell.execute_reply.started":"2024-12-05T00:12:41.056068Z","shell.execute_reply":"2024-12-05T00:12:41.091312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}